{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN56tzx1KEGwoJnJk5ZSZhZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PMunyao/self-aware-ai/blob/master/snn_with_recon_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZIiBWkksX5D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from .snn_layers import *\n",
        "from .fsvae_prior import *\n",
        "from .fsvae_posterior import *\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import global_v as glv\n",
        "\n",
        "\n",
        "class FSVAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        in_channels = glv.network_config['in_channels']\n",
        "        latent_dim = glv.network_config['latent_dim']\n",
        "        self.latent_dim = latent_dim\n",
        "        self.n_steps = glv.network_config['n_steps']\n",
        "\n",
        "        self.k = glv.network_config['k']\n",
        "\n",
        "        hidden_dims = [32, 64, 128, 256]\n",
        "        self.hidden_dims = hidden_dims.copy()\n",
        "\n",
        "        # Build Encoder\n",
        "        modules = []\n",
        "        is_first_conv = True\n",
        "        for h_dim in hidden_dims:\n",
        "            modules.append(\n",
        "                tdConv(in_channels,\n",
        "                        out_channels=h_dim,\n",
        "                        kernel_size=3, \n",
        "                        stride=2, \n",
        "                        padding=1,\n",
        "                        bias=True,\n",
        "                        bn=tdBatchNorm(h_dim),\n",
        "                        spike=LIFSpike(),\n",
        "                        is_first_conv=is_first_conv)\n",
        "            )\n",
        "            in_channels = h_dim\n",
        "            is_first_conv = False\n",
        "        \n",
        "        self.encoder = nn.Sequential(*modules)\n",
        "        self.before_latent_layer = tdLinear(hidden_dims[-1]*4,\n",
        "                                            latent_dim,\n",
        "                                            bias=True,\n",
        "                                            bn=tdBatchNorm(latent_dim),\n",
        "                                            spike=LIFSpike())\n",
        "\n",
        "        self.prior = PriorBernoulliSTBP(self.k)\n",
        "        \n",
        "        self.posterior = PosteriorBernoulliSTBP(self.k)\n",
        "\n",
        "        # Build Decoder\n",
        "        modules = []\n",
        "        \n",
        "        self.decoder_input = tdLinear(latent_dim, \n",
        "                                        hidden_dims[-1] * 4, \n",
        "                                        bias=True,\n",
        "                                        bn=tdBatchNorm(hidden_dims[-1] * 4),\n",
        "                                        spike=LIFSpike())\n",
        "        \n",
        "        hidden_dims.reverse()\n",
        "\n",
        "        for i in range(len(hidden_dims) - 1):\n",
        "            modules.append(\n",
        "                    tdConvTranspose(hidden_dims[i],\n",
        "                                    hidden_dims[i + 1],\n",
        "                                    kernel_size=3,\n",
        "                                    stride = 2,\n",
        "                                    padding=1,\n",
        "                                    output_padding=1,\n",
        "                                    bias=True,\n",
        "                                    bn=tdBatchNorm(hidden_dims[i+1]),\n",
        "                                    spike=LIFSpike())\n",
        "            )\n",
        "        self.decoder = nn.Sequential(*modules)\n",
        "\n",
        "        self.final_layer = nn.Sequential(\n",
        "                            tdConvTranspose(hidden_dims[-1],\n",
        "                                            hidden_dims[-1],\n",
        "                                            kernel_size=3,\n",
        "                                            stride=2,\n",
        "                                            padding=1,\n",
        "                                            output_padding=1,\n",
        "                                            bias=True,\n",
        "                                            bn=tdBatchNorm(hidden_dims[-1]),\n",
        "                                            spike=LIFSpike()),\n",
        "                            tdConvTranspose(hidden_dims[-1], \n",
        "                                            out_channels=glv.network_config['in_channels'],\n",
        "                                            kernel_size=3, \n",
        "                                            padding=1,\n",
        "                                            bias=True,\n",
        "                                            bn=None,\n",
        "                                            spike=None)\n",
        "        )\n",
        "\n",
        "        self.p = 0\n",
        "\n",
        "        self.membrane_output_layer = MembraneOutputLayer()\n",
        "\n",
        "        self.psp = PSP()\n",
        "\n",
        "    def forward(self, x, scheduled=False):\n",
        "        sampled_z, q_z, p_z = self.encode(x, scheduled)\n",
        "        x_recon = self.decode(sampled_z)\n",
        "        return x_recon, q_z, p_z, sampled_z\n",
        "    \n",
        "    def encode(self, x, scheduled=False):\n",
        "        x = self.encoder(x) # (N,C,H,W,T)\n",
        "        x = torch.flatten(x, start_dim=1, end_dim=3) # (N,C*H*W,T)\n",
        "        latent_x = self.before_latent_layer(x) # (N,latent_dim,T)\n",
        "        sampled_z, q_z = self.posterior(latent_x) # sampled_z:(B,C,1,1,T), q_z:(B,C,k,T)\n",
        "\n",
        "        p_z = self.prior(sampled_z, scheduled, self.p)\n",
        "        return sampled_z, q_z, p_z\n",
        "\n",
        "    def decode(self, z):\n",
        "        result = self.decoder_input(z) # (N,C*H*W,T)\n",
        "        result = result.view(result.shape[0], self.hidden_dims[-1], 2, 2, self.n_steps) # (N,C,H,W,T)\n",
        "        result = self.decoder(result)# (N,C,H,W,T)\n",
        "        result = self.final_layer(result)# (N,C,H,W,T)\n",
        "        out = torch.tanh(self.membrane_output_layer(result))        \n",
        "        return out\n",
        "\n",
        "    def sample(self, batch_size=64):\n",
        "        sampled_z = self.prior.sample(batch_size)\n",
        "        sampled_x = self.decode(sampled_z)\n",
        "        return sampled_x, sampled_z\n",
        "        \n",
        "    def loss_function_mmd(self, input_img, recons_img, q_z, p_z):\n",
        "        \"\"\"\n",
        "        q_z is q(z|x): (N,latent_dim,k,T)\n",
        "        p_z is p(z): (N,latent_dim,k,T)\n",
        "        \"\"\"\n",
        "        recons_loss = F.mse_loss(recons_img, input_img)\n",
        "        q_z_ber = torch.mean(q_z, dim=2) # (N, latent_dim, T)\n",
        "        p_z_ber = torch.mean(p_z, dim=2) # (N, latent_dim, T)\n",
        "\n",
        "        #kld_loss = torch.mean((q_z_ber - p_z_ber)**2)\n",
        "        mmd_loss = torch.mean((self.psp(q_z_ber)-self.psp(p_z_ber))**2)\n",
        "        loss = recons_loss + mmd_loss\n",
        "        return {'loss': loss, 'Reconstruction_Loss':recons_loss, 'Distance_Loss': mmd_loss}\n",
        "\n",
        "    def loss_function_kld(self, input_img, recons_img, q_z, p_z):\n",
        "        \"\"\"\n",
        "        q_z is q(z|x): (N,latent_dim,k,T)\n",
        "        p_z is p(z): (N,latent_dim,k,T)\n",
        "        \"\"\"\n",
        "        recons_loss = F.mse_loss(recons_img, input_img)\n",
        "        prob_q = torch.mean(q_z, dim=2) # (N, latent_dim, T)\n",
        "        prob_p = torch.mean(p_z, dim=2) # (N, latent_dim, T)\n",
        "        \n",
        "        kld_loss = prob_q * torch.log((prob_q+1e-2)/(prob_p+1e-2)) + (1-prob_q)*torch.log((1-prob_q+1e-2)/(1-prob_p+1e-2))\n",
        "        kld_loss = torch.mean(torch.sum(kld_loss, dim=(1,2)))\n",
        "\n",
        "        loss = recons_loss + 1e-4 * kld_loss\n",
        "        return {'loss': loss, 'Reconstruction_Loss':recons_loss, 'Distance_Loss': kld_loss}\n",
        "    def weight_clipper(self):\n",
        "        with torch.no_grad():\n",
        "            for p in self.parameters():\n",
        "                p.data.clamp_(-4,4)\n",
        "\n",
        "    def update_p(self, epoch, max_epoch):\n",
        "        init_p = 0.1\n",
        "        last_p = 0.3\n",
        "        self.p = (last_p-init_p) * epoch / max_epoch + init_p\n",
        "    \n",
        "    #add a function for reconstruction probability\n",
        "    def reconstruction_prob(self, input_img, recons_img):\n",
        "        recons_loss = F.mse_loss(recons_img, input_img)\n",
        "        return recons_loss\n",
        "        \n",
        "    #using a different function for reconstruction probablity\n",
        "    def reconstruction_prob_diff(self, input_img, recons_img):\n",
        "        recons_loss = F.mse_loss(recons_img, input_img)\n",
        "        recons_loss = recons_loss.sum()\n",
        "        return recons_loss"
      ]
    }
  ]
}